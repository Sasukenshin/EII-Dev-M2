{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # TP1. Fully Connected Networks\n",
    " \n",
    " #### Sciences U, 2019-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Classification on Text Data(Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287",
    "_uuid": "717bb968c36b9325c7d4cae5724a3672e49ff243"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc2702e-d6f4-df5f-b80e-50ab23a6d29e",
    "_uuid": "9b520acffb5cd85d0e1ada968ad0f12cee33a4b5"
   },
   "source": [
    "**Question 1: Load the Sentiment.csv file, only keep columns `text` and `sentiment` and print out first 10 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   Neutral  RT @NancyLeeGrahn: How did everyone feel about...\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "2   Neutral  RT @TJMShow: No mention of Tamir Rice and the ...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5  Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6  Negative  RT @warriorwoman91: I liked her and was happy ...\n",
       "7   Neutral  Going on #MSNBC Live with @ThomasARoberts arou...\n",
       "8  Negative  Deer in the headlights RT @lizzwinstead: Ben C...\n",
       "9  Negative  RT @NancyOsborne180: Last night's debate prove..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/matt/EII/Archis des applications (UC8-A.2)/w1-a/data/Sentiment.csv'\n",
    "sentiments = pd.read_csv(file_path, usecols=['text', 'sentiment'])\n",
    "sentiments.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2. Remove all rows with label Neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@JGreenDC @realDonaldTrump In all fairness #Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @WayneDupreeShow: Just woke up to tweet thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Me reading my family's comments about how grea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "1   Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "3   Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4   Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5   Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6   Negative  RT @warriorwoman91: I liked her and was happy ...\n",
       "8   Negative  Deer in the headlights RT @lizzwinstead: Ben C...\n",
       "9   Negative  RT @NancyOsborne180: Last night's debate prove...\n",
       "10  Negative  @JGreenDC @realDonaldTrump In all fairness #Bi...\n",
       "11  Positive  RT @WayneDupreeShow: Just woke up to tweet thi...\n",
       "12  Negative  Me reading my family's comments about how grea..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = sentiments[sentiments.sentiment != 'Neutral']\n",
    "sentiments.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3. Print the number of Positive and Negative rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 2)\n",
      "(8493, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sentiments[sentiments.sentiment == 'Positive'].shape)\n",
    "print(sentiments[sentiments.sentiment == 'Negative'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the number of Negative rows is higher than the number of Positive rows. Today, we only forcus on balanced data, and so we would like to make the two equal.\n",
    "\n",
    "**Question 4. Remove some Negative rows so that #Positive and Negative rows are equal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 2)\n",
      "(2236, 2)\n"
     ]
    }
   ],
   "source": [
    "# Number of values to delete\n",
    "pos_rows_count, _ = sentiments[sentiments.sentiment == 'Positive'].shape\n",
    "neg_rows_count, _ = sentiments[sentiments.sentiment == 'Negative'].shape\n",
    "remove_n = neg_rows_count - pos_rows_count\n",
    "\n",
    "# Index to drop\n",
    "indexes = sentiments[sentiments.sentiment == 'Negative'].index\n",
    "drop_indices = np.random.choice(indexes.values, remove_n, replace=False)\n",
    "\n",
    "# Drop random Negative sentiment\n",
    "sentiments = sentiments.drop(drop_indices)\n",
    "\n",
    "# Check\n",
    "print(sentiments[sentiments.sentiment == 'Positive'].shape)\n",
    "print(sentiments[sentiments.sentiment == 'Negative'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert all data into lower case and remove all special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "d0f8b4542106a279f7398db7285ae5e370b2e813"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two examples of the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt robgeorge that carly fiorina is trending  hours after her debate  above any of the men in justcompleted gopdebate says shes on \n",
      "rt danscavino gopdebate w realdonaldtrump delivered the highest ratings in the history of presidential debates trump2016 httptco\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[1].text)\n",
    "print(data.iloc[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to map each sentence to an array of tokens, each word is a token. To make the array having fixed length, we pad enough 0 to the begining of each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4472, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the length of each array is 29. Here is the array corresponding to the two sentences above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    3  346  134    2\n",
      "  751    1   29   38  310   49  183    7  115 1087   14 1088 1766  802]\n",
      "[   0    0    0    0    0    0    0    0    0    3   20  182  172    9\n",
      "  625  100  223   25 1460  162    7    2  249   14    1  197  566   17]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5. Make label data corresponding to X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace sentiment by integer\n",
    "sentiments['sentiment'].replace(['Positive','Negative'],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4472, 2)\n"
     ]
    }
   ],
   "source": [
    "y = sentiments['sentiment']\n",
    "yc = to_categorical(y)\n",
    "print(yc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6. Split train/test sets randomly with ratio 2:1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\t (2996, 28) (2996, 2)\n",
      "test data:\t (1476, 28) (1476, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, yc, test_size=0.33, random_state=42)\n",
    "\n",
    "print('train data:\\t', x_train.shape, y_train.shape)\n",
    "print('test data:\\t', x_test.shape, y_test.shape)\n",
    "# Expect \n",
    "# (2996, 28) (2996, 2)\n",
    "# (1476, 28) (1476, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7. Build a quick Fully Connected network to obtain 55\\% accuracy on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "2996/2996 [==============================] - 1s 211us/step - loss: 33.4682 - accuracy: 0.5227\n",
      "Epoch 2/50\n",
      "2996/2996 [==============================] - 0s 58us/step - loss: 10.3190 - accuracy: 0.5594\n",
      "Epoch 3/50\n",
      "2996/2996 [==============================] - 0s 63us/step - loss: 6.3348 - accuracy: 0.6015\n",
      "Epoch 4/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 4.2884 - accuracy: 0.6439\n",
      "Epoch 5/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 3.2835 - accuracy: 0.6519\n",
      "Epoch 6/50\n",
      "2996/2996 [==============================] - 0s 88us/step - loss: 2.5931 - accuracy: 0.6759\n",
      "Epoch 7/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 2.1329 - accuracy: 0.6963\n",
      "Epoch 8/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 1.8209 - accuracy: 0.7170\n",
      "Epoch 9/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 1.6006 - accuracy: 0.7300\n",
      "Epoch 10/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 1.3920 - accuracy: 0.7403\n",
      "Epoch 11/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 1.1544 - accuracy: 0.7530\n",
      "Epoch 12/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 1.1534 - accuracy: 0.7520\n",
      "Epoch 13/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.9327 - accuracy: 0.7724\n",
      "Epoch 14/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.8546 - accuracy: 0.7777\n",
      "Epoch 15/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.7635 - accuracy: 0.7967\n",
      "Epoch 16/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.6499 - accuracy: 0.7977\n",
      "Epoch 17/50\n",
      "2996/2996 [==============================] - 0s 58us/step - loss: 0.6540 - accuracy: 0.8081\n",
      "Epoch 18/50\n",
      "2996/2996 [==============================] - 0s 56us/step - loss: 0.5524 - accuracy: 0.8201\n",
      "Epoch 19/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.6356 - accuracy: 0.8131\n",
      "Epoch 20/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.5863 - accuracy: 0.8154\n",
      "Epoch 21/50\n",
      "2996/2996 [==============================] - 0s 56us/step - loss: 0.5255 - accuracy: 0.8308\n",
      "Epoch 22/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.4927 - accuracy: 0.8311\n",
      "Epoch 23/50\n",
      "2996/2996 [==============================] - 0s 57us/step - loss: 0.5645 - accuracy: 0.8261\n",
      "Epoch 24/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.4643 - accuracy: 0.8411\n",
      "Epoch 25/50\n",
      "2996/2996 [==============================] - 0s 61us/step - loss: 0.4083 - accuracy: 0.8548\n",
      "Epoch 26/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.3797 - accuracy: 0.8611\n",
      "Epoch 27/50\n",
      "2996/2996 [==============================] - 0s 58us/step - loss: 0.3315 - accuracy: 0.8725\n",
      "Epoch 28/50\n",
      "2996/2996 [==============================] - 0s 64us/step - loss: 0.3756 - accuracy: 0.8665\n",
      "Epoch 29/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.3463 - accuracy: 0.8615\n",
      "Epoch 30/50\n",
      "2996/2996 [==============================] - 0s 58us/step - loss: 0.3028 - accuracy: 0.8795\n",
      "Epoch 31/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.3188 - accuracy: 0.8855\n",
      "Epoch 32/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.3571 - accuracy: 0.8665\n",
      "Epoch 33/50\n",
      "2996/2996 [==============================] - 0s 56us/step - loss: 0.3883 - accuracy: 0.8772\n",
      "Epoch 34/50\n",
      "2996/2996 [==============================] - 0s 57us/step - loss: 0.3730 - accuracy: 0.8638\n",
      "Epoch 35/50\n",
      "2996/2996 [==============================] - 0s 56us/step - loss: 0.4026 - accuracy: 0.8605\n",
      "Epoch 36/50\n",
      "2996/2996 [==============================] - 0s 58us/step - loss: 0.3319 - accuracy: 0.8778\n",
      "Epoch 37/50\n",
      "2996/2996 [==============================] - 0s 61us/step - loss: 0.2887 - accuracy: 0.8848\n",
      "Epoch 38/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.2628 - accuracy: 0.8949\n",
      "Epoch 39/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.2817 - accuracy: 0.8995\n",
      "Epoch 40/50\n",
      "2996/2996 [==============================] - 0s 59us/step - loss: 0.3538 - accuracy: 0.8752\n",
      "Epoch 41/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.2624 - accuracy: 0.8985\n",
      "Epoch 42/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.3517 - accuracy: 0.8768\n",
      "Epoch 43/50\n",
      "2996/2996 [==============================] - 0s 61us/step - loss: 0.3069 - accuracy: 0.8828\n",
      "Epoch 44/50\n",
      "2996/2996 [==============================] - 0s 57us/step - loss: 0.2756 - accuracy: 0.8935\n",
      "Epoch 45/50\n",
      "2996/2996 [==============================] - 0s 60us/step - loss: 0.2512 - accuracy: 0.9065\n",
      "Epoch 46/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.2650 - accuracy: 0.9079\n",
      "Epoch 47/50\n",
      "2996/2996 [==============================] - 0s 63us/step - loss: 0.2409 - accuracy: 0.9049\n",
      "Epoch 48/50\n",
      "2996/2996 [==============================] - 0s 63us/step - loss: 0.2798 - accuracy: 0.9022\n",
      "Epoch 49/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.2988 - accuracy: 0.8949\n",
      "Epoch 50/50\n",
      "2996/2996 [==============================] - 0s 62us/step - loss: 0.2764 - accuracy: 0.9039\n",
      "2996/2996 [==============================] - 0s 52us/step\n",
      "1476/1476 [==============================] - 0s 31us/step\n",
      "train_acc 0.9105473756790161\n",
      "test_acc 0.6111111044883728\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=28, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64)\n",
    "\n",
    "_, train_acc = model.evaluate(x_train, y_train, batch_size=64)\n",
    "_, test_acc = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print('train_acc', train_acc)\n",
    "print('test_acc', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8. Improve the architecture to achieve 65\\% accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train = (x_train - np.mean(x_train))/np.std(x_train)\n",
    "x_test = (x_test - np.mean(x_test))/np.std(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2996/2996 [==============================] - 1s 241us/step - loss: 0.6884 - accuracy: 0.5350\n",
      "Epoch 2/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.6630 - accuracy: 0.5955\n",
      "Epoch 3/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.6402 - accuracy: 0.6318\n",
      "Epoch 4/50\n",
      "2996/2996 [==============================] - 0s 71us/step - loss: 0.6125 - accuracy: 0.6676\n",
      "Epoch 5/50\n",
      "2996/2996 [==============================] - 0s 64us/step - loss: 0.5862 - accuracy: 0.6903\n",
      "Epoch 6/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.5576 - accuracy: 0.7126\n",
      "Epoch 7/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.5331 - accuracy: 0.7226\n",
      "Epoch 8/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.5073 - accuracy: 0.7447\n",
      "Epoch 9/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.4807 - accuracy: 0.7617\n",
      "Epoch 10/50\n",
      "2996/2996 [==============================] - 0s 64us/step - loss: 0.4592 - accuracy: 0.7794\n",
      "Epoch 11/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.4365 - accuracy: 0.7860\n",
      "Epoch 12/50\n",
      "2996/2996 [==============================] - 0s 66us/step - loss: 0.4274 - accuracy: 0.7931\n",
      "Epoch 13/50\n",
      "2996/2996 [==============================] - 0s 71us/step - loss: 0.3978 - accuracy: 0.8181\n",
      "Epoch 14/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.3931 - accuracy: 0.8201\n",
      "Epoch 15/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.3922 - accuracy: 0.8204\n",
      "Epoch 16/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.3593 - accuracy: 0.8348\n",
      "Epoch 17/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.3482 - accuracy: 0.8461\n",
      "Epoch 18/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.3284 - accuracy: 0.8518\n",
      "Epoch 19/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.3139 - accuracy: 0.8635\n",
      "Epoch 20/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.3055 - accuracy: 0.8678\n",
      "Epoch 21/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.2962 - accuracy: 0.8718\n",
      "Epoch 22/50\n",
      "2996/2996 [==============================] - 0s 66us/step - loss: 0.2934 - accuracy: 0.8718\n",
      "Epoch 23/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.2785 - accuracy: 0.8745\n",
      "Epoch 24/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.2560 - accuracy: 0.8892\n",
      "Epoch 25/50\n",
      "2996/2996 [==============================] - 0s 66us/step - loss: 0.2765 - accuracy: 0.8798\n",
      "Epoch 26/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.2437 - accuracy: 0.8985\n",
      "Epoch 27/50\n",
      "2996/2996 [==============================] - 0s 65us/step - loss: 0.2421 - accuracy: 0.8972\n",
      "Epoch 28/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.2384 - accuracy: 0.8999\n",
      "Epoch 29/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.2261 - accuracy: 0.9109\n",
      "Epoch 30/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.2103 - accuracy: 0.9169\n",
      "Epoch 31/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.2194 - accuracy: 0.9122\n",
      "Epoch 32/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.2080 - accuracy: 0.9136\n",
      "Epoch 33/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.2027 - accuracy: 0.9149\n",
      "Epoch 34/50\n",
      "2996/2996 [==============================] - 0s 75us/step - loss: 0.1968 - accuracy: 0.9159\n",
      "Epoch 35/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.1995 - accuracy: 0.9199\n",
      "Epoch 36/50\n",
      "2996/2996 [==============================] - 0s 74us/step - loss: 0.1930 - accuracy: 0.9172\n",
      "Epoch 37/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.1853 - accuracy: 0.9232\n",
      "Epoch 38/50\n",
      "2996/2996 [==============================] - 0s 72us/step - loss: 0.1971 - accuracy: 0.9192\n",
      "Epoch 39/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.1744 - accuracy: 0.9299\n",
      "Epoch 40/50\n",
      "2996/2996 [==============================] - 0s 72us/step - loss: 0.1814 - accuracy: 0.9276\n",
      "Epoch 41/50\n",
      "2996/2996 [==============================] - 0s 71us/step - loss: 0.1879 - accuracy: 0.9229\n",
      "Epoch 42/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.1748 - accuracy: 0.9286\n",
      "Epoch 43/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.1721 - accuracy: 0.9269\n",
      "Epoch 44/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.1711 - accuracy: 0.9326\n",
      "Epoch 45/50\n",
      "2996/2996 [==============================] - 0s 67us/step - loss: 0.1638 - accuracy: 0.9339\n",
      "Epoch 46/50\n",
      "2996/2996 [==============================] - 0s 71us/step - loss: 0.1646 - accuracy: 0.9306\n",
      "Epoch 47/50\n",
      "2996/2996 [==============================] - 0s 70us/step - loss: 0.1796 - accuracy: 0.9246\n",
      "Epoch 48/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.1680 - accuracy: 0.9309\n",
      "Epoch 49/50\n",
      "2996/2996 [==============================] - 0s 68us/step - loss: 0.1760 - accuracy: 0.9272\n",
      "Epoch 50/50\n",
      "2996/2996 [==============================] - 0s 69us/step - loss: 0.1705 - accuracy: 0.9292\n",
      "2996/2996 [==============================] - 0s 57us/step\n",
      "1476/1476 [==============================] - 0s 32us/step\n",
      "train_acc 0.9469292163848877\n",
      "test_acc 0.6219512224197388\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=28, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64)\n",
    "\n",
    "_, train_acc = model.evaluate(x_train, y_train, batch_size=64)\n",
    "_, test_acc = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print('train_acc', train_acc)\n",
    "print('test_acc', test_acc)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
