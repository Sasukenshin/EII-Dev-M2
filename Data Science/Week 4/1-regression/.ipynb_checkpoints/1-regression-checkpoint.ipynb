{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4. Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate data with 20 features; among them, 10 features are uncorrelated to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x): # some favorite function\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        s += (i%2) * x[i] * np.tan(x[i]) * np.sqrt(i+1)\n",
    "    return 10*s\n",
    "\n",
    "np.random.seed(999)\n",
    "a = np.arange(0,1,0.01)\n",
    "X = np.random.choice(a, size= 2000, replace=True).reshape((100,20))\n",
    "\n",
    "y = np.empty(len(X))\n",
    "for i in range(len(X)):\n",
    "    y[i] = g(X[i])\n",
    "\n",
    "X_train = X[:50]\n",
    "y_train = y[:50]\n",
    "X_test = X[50:]\n",
    "y_test = y[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64, 0.92, 0.97, 0.72, 0.97, 0.91, 0.31, 0.89, 0.51, 0.16, 0.08,\n",
       "        0.08, 0.48, 0.69, 0.66, 0.11, 0.11, 0.21, 0.87, 0.5 ],\n",
       "       [0.62, 0.71, 0.17, 0.62, 0.43, 0.32, 0.04, 0.13, 0.43, 0.84, 0.72,\n",
       "        0.27, 0.5 , 0.23, 0.52, 0.84, 0.05, 0.43, 0.81, 0.95],\n",
       "       [0.54, 0.42, 0.88, 0.57, 0.49, 0.43, 0.01, 0.78, 0.7 , 0.03, 0.72,\n",
       "        0.09, 0.78, 0.16, 0.63, 0.49, 0.58, 0.31, 0.46, 0.52],\n",
       "       [0.76, 0.14, 0.48, 0.06, 0.04, 0.87, 0.67, 0.52, 0.63, 0.25, 0.43,\n",
       "        0.94, 0.27, 0.22, 0.78, 0.39, 0.3 , 0.51, 0.63, 0.48],\n",
       "       [0.75, 0.52, 0.04, 0.54, 0.56, 0.38, 0.78, 0.76, 0.59, 0.48, 0.15,\n",
       "        0.22, 0.71, 0.15, 0.49, 0.02, 0.21, 0.46, 0.11, 0.31],\n",
       "       [0.6 , 0.58, 0.98, 0.33, 0.99, 0.35, 0.66, 0.74, 0.19, 0.35, 0.12,\n",
       "        0.04, 0.01, 0.06, 0.37, 0.89, 0.11, 0.79, 0.02, 0.66],\n",
       "       [0.83, 0.88, 0.8 , 0.48, 0.89, 0.16, 0.23, 0.16, 0.69, 0.77, 0.61,\n",
       "        0.98, 0.94, 0.06, 0.08, 0.89, 0.84, 0.25, 0.5 , 0.05],\n",
       "       [0.72, 0.14, 0.19, 0.67, 0.25, 0.89, 0.09, 0.13, 0.31, 0.06, 0.61,\n",
       "        0.1 , 0.15, 0.72, 0.41, 0.44, 0.9 , 0.04, 0.64, 0.69],\n",
       "       [0.29, 0.55, 0.63, 0.24, 0.12, 0.84, 0.21, 0.48, 0.8 , 0.48, 0.51,\n",
       "        0.05, 0.01, 0.05, 0.92, 0.43, 0.38, 0.79, 0.81, 0.38],\n",
       "       [0.02, 0.95, 0.56, 0.82, 0.73, 0.37, 0.77, 0.58, 0.11, 0.92, 0.43,\n",
       "        0.74, 0.33, 0.29, 0.6 , 0.47, 0.78, 0.35, 0.53, 0.29],\n",
       "       [0.76, 0.92, 0.51, 0.83, 0.17, 0.86, 0.03, 0.54, 0.54, 0.03, 0.5 ,\n",
       "        0.22, 0.69, 0.64, 0.7 , 0.91, 0.85, 0.48, 0.81, 0.64],\n",
       "       [0.49, 0.1 , 0.61, 0.56, 0.76, 0.43, 0.67, 0.25, 0.36, 0.63, 0.31,\n",
       "        0.39, 0.15, 0.39, 0.58, 0.81, 0.4 , 0.55, 0.47, 0.23],\n",
       "       [0.41, 0.98, 0.13, 0.5 , 0.62, 0.81, 0.34, 0.1 , 0.68, 0.18, 0.8 ,\n",
       "        0.13, 0.77, 0.19, 0.42, 0.2 , 0.57, 0.99, 0.22, 0.38],\n",
       "       [0.19, 0.06, 0.81, 0.04, 0.8 , 0.43, 0.46, 0.65, 0.42, 0.24, 0.02,\n",
       "        0.71, 0.2 , 0.35, 0.39, 0.58, 0.7 , 0.37, 0.93, 0.6 ],\n",
       "       [0.32, 0.85, 0.15, 0.34, 0.52, 0.13, 0.  , 0.5 , 0.54, 0.71, 0.8 ,\n",
       "        0.92, 0.28, 0.73, 0.14, 0.96, 0.31, 0.74, 0.36, 0.49],\n",
       "       [0.26, 0.82, 0.48, 0.74, 0.73, 0.73, 0.16, 0.97, 0.39, 0.1 , 0.31,\n",
       "        0.49, 0.59, 0.74, 0.8 , 0.38, 0.06, 0.52, 0.54, 0.05],\n",
       "       [0.02, 0.39, 0.58, 0.79, 0.41, 0.29, 0.52, 0.8 , 0.44, 0.3 , 0.58,\n",
       "        0.95, 0.81, 0.65, 0.24, 0.1 , 0.7 , 0.82, 0.24, 0.76],\n",
       "       [0.61, 0.59, 0.16, 0.07, 0.95, 0.01, 0.67, 0.27, 0.16, 0.41, 0.82,\n",
       "        0.45, 0.73, 0.62, 0.33, 0.15, 0.32, 0.74, 0.77, 0.13],\n",
       "       [0.5 , 0.85, 0.41, 0.48, 0.16, 0.71, 0.27, 0.48, 0.5 , 0.6 , 0.99,\n",
       "        0.46, 0.51, 0.  , 0.6 , 0.71, 0.03, 0.9 , 0.53, 0.93],\n",
       "       [0.62, 0.02, 0.83, 0.14, 0.27, 0.85, 0.77, 0.29, 0.92, 0.7 , 0.96,\n",
       "        0.53, 0.3 , 0.48, 0.8 , 0.58, 0.71, 0.2 , 0.28, 0.08],\n",
       "       [0.03, 0.58, 0.24, 0.7 , 0.35, 0.18, 0.39, 0.37, 0.1 , 0.8 , 0.67,\n",
       "        0.11, 0.97, 0.48, 0.05, 0.06, 0.76, 0.3 , 0.63, 0.81],\n",
       "       [0.45, 0.04, 0.41, 0.98, 0.88, 0.06, 0.83, 0.24, 0.51, 0.26, 0.7 ,\n",
       "        0.43, 0.72, 0.88, 0.13, 0.4 , 0.19, 0.79, 0.23, 0.46],\n",
       "       [0.85, 0.89, 0.29, 0.84, 0.57, 0.32, 0.92, 0.62, 0.35, 0.92, 0.94,\n",
       "        0.42, 0.5 , 0.69, 0.72, 0.18, 0.2 , 0.91, 0.85, 0.16],\n",
       "       [0.84, 0.91, 0.74, 0.49, 0.65, 0.43, 0.74, 0.77, 0.68, 0.23, 0.14,\n",
       "        0.93, 0.97, 0.54, 0.09, 0.91, 0.27, 0.34, 0.38, 0.28],\n",
       "       [0.3 , 0.27, 0.77, 0.74, 0.91, 0.59, 0.41, 0.46, 0.7 , 0.41, 0.33,\n",
       "        0.73, 0.72, 0.26, 0.92, 0.73, 0.49, 0.23, 0.74, 0.23],\n",
       "       [0.51, 0.7 , 0.66, 0.44, 0.03, 0.81, 0.14, 0.93, 0.27, 0.58, 0.67,\n",
       "        0.85, 0.24, 0.74, 0.3 , 0.09, 0.  , 0.36, 0.99, 0.21],\n",
       "       [0.08, 0.63, 0.44, 0.8 , 0.02, 0.72, 0.02, 0.33, 0.08, 0.07, 0.64,\n",
       "        0.9 , 0.97, 0.48, 0.91, 0.88, 0.62, 0.28, 0.31, 0.97],\n",
       "       [0.31, 0.7 , 0.58, 0.73, 0.39, 0.01, 0.05, 0.55, 0.87, 0.33, 0.21,\n",
       "        0.07, 0.93, 0.93, 0.29, 0.15, 0.7 , 0.48, 0.77, 0.88],\n",
       "       [0.79, 0.97, 0.2 , 0.99, 0.65, 0.65, 0.91, 0.92, 0.85, 0.03, 0.58,\n",
       "        0.81, 0.96, 0.15, 0.89, 0.9 , 0.05, 0.91, 0.58, 0.56],\n",
       "       [0.29, 0.76, 0.96, 0.23, 0.33, 0.51, 0.25, 0.54, 0.11, 0.53, 0.33,\n",
       "        0.09, 0.06, 0.73, 0.92, 0.98, 0.5 , 0.44, 0.92, 0.91],\n",
       "       [0.45, 0.8 , 0.87, 0.85, 0.91, 0.16, 0.05, 0.44, 0.23, 0.76, 0.09,\n",
       "        0.13, 0.65, 0.84, 0.17, 0.83, 0.79, 0.96, 0.4 , 0.77],\n",
       "       [0.21, 0.97, 0.03, 0.27, 0.24, 0.9 , 0.41, 0.85, 0.71, 0.85, 0.95,\n",
       "        0.41, 0.66, 0.28, 0.53, 0.93, 0.81, 0.88, 0.62, 0.09],\n",
       "       [0.88, 0.46, 0.42, 0.3 , 0.82, 0.38, 0.16, 0.83, 0.04, 0.96, 0.49,\n",
       "        0.97, 0.84, 0.55, 0.08, 0.22, 0.1 , 0.86, 0.33, 0.4 ],\n",
       "       [0.61, 0.61, 0.25, 0.81, 0.49, 0.26, 0.87, 0.  , 0.74, 0.15, 0.07,\n",
       "        0.89, 0.81, 0.11, 0.79, 0.55, 0.37, 0.99, 0.05, 0.12],\n",
       "       [0.01, 0.2 , 0.63, 0.73, 0.77, 0.87, 0.24, 0.79, 0.17, 0.1 , 0.12,\n",
       "        0.67, 0.82, 0.98, 0.61, 0.67, 0.55, 0.72, 0.75, 0.96],\n",
       "       [0.81, 0.76, 0.6 , 0.37, 0.05, 0.99, 0.91, 0.74, 0.27, 0.34, 0.3 ,\n",
       "        0.12, 0.56, 0.92, 0.84, 0.37, 0.51, 0.05, 0.53, 0.43],\n",
       "       [0.3 , 0.72, 0.79, 0.2 , 0.34, 0.78, 0.64, 0.23, 0.44, 0.81, 0.78,\n",
       "        0.99, 0.89, 0.63, 0.61, 0.34, 0.38, 0.71, 0.66, 0.93],\n",
       "       [0.76, 0.76, 0.7 , 0.43, 0.  , 0.22, 0.81, 0.34, 0.26, 0.13, 0.63,\n",
       "        0.15, 0.46, 0.53, 0.59, 0.12, 0.06, 0.06, 0.52, 0.86],\n",
       "       [0.43, 0.1 , 0.08, 0.24, 0.47, 0.87, 0.09, 0.23, 0.89, 0.66, 0.77,\n",
       "        0.4 , 0.28, 0.73, 0.23, 0.33, 0.1 , 0.56, 0.12, 0.26],\n",
       "       [0.86, 0.7 , 0.27, 0.36, 0.99, 0.23, 0.59, 0.65, 0.75, 0.86, 0.21,\n",
       "        0.1 , 0.53, 0.17, 0.55, 0.01, 0.64, 0.9 , 0.22, 0.47],\n",
       "       [0.26, 0.59, 0.77, 0.5 , 0.9 , 0.64, 0.35, 0.22, 0.15, 0.61, 0.6 ,\n",
       "        0.5 , 0.85, 0.13, 0.4 , 0.52, 0.46, 0.83, 0.79, 0.79],\n",
       "       [0.67, 0.43, 0.71, 0.92, 0.12, 0.3 , 0.27, 0.54, 0.98, 0.34, 0.05,\n",
       "        0.12, 0.83, 0.08, 0.27, 0.83, 0.83, 0.17, 0.09, 0.56],\n",
       "       [0.26, 0.39, 0.  , 0.11, 0.18, 0.74, 0.58, 0.09, 0.69, 0.38, 0.76,\n",
       "        0.33, 0.87, 0.19, 0.1 , 0.35, 0.6 , 0.06, 0.33, 0.72],\n",
       "       [0.37, 0.98, 0.14, 0.12, 0.48, 0.49, 0.65, 0.73, 0.01, 0.77, 0.73,\n",
       "        0.23, 0.28, 0.93, 0.46, 0.98, 0.7 , 0.12, 0.69, 0.82],\n",
       "       [0.18, 0.24, 0.54, 0.85, 0.99, 0.5 , 0.53, 0.03, 0.28, 0.13, 0.09,\n",
       "        0.24, 0.29, 0.25, 0.06, 0.98, 0.8 , 0.42, 0.52, 0.02],\n",
       "       [0.93, 0.95, 0.83, 0.39, 0.07, 0.97, 0.12, 0.16, 0.17, 0.86, 0.52,\n",
       "        0.1 , 0.33, 0.34, 0.41, 0.12, 0.3 , 0.36, 0.2 , 0.16],\n",
       "       [0.35, 0.54, 0.63, 0.31, 0.66, 0.54, 0.26, 0.15, 0.37, 0.8 , 0.14,\n",
       "        0.08, 0.25, 0.16, 0.34, 0.6 , 0.31, 0.41, 0.11, 0.29],\n",
       "       [0.14, 0.77, 0.12, 0.97, 0.8 , 0.48, 0.98, 0.98, 0.8 , 0.98, 0.51,\n",
       "        0.18, 0.73, 0.33, 0.67, 0.83, 0.93, 0.7 , 0.51, 0.28],\n",
       "       [0.33, 0.85, 0.65, 0.79, 0.54, 0.39, 0.76, 0.26, 0.77, 0.75, 0.5 ,\n",
       "        0.66, 0.31, 0.25, 0.28, 0.37, 0.39, 0.42, 0.15, 0.71],\n",
       "       [0.76, 0.3 , 0.27, 0.21, 0.2 , 0.65, 0.59, 0.03, 0.16, 0.2 , 0.05,\n",
       "        0.87, 0.33, 0.54, 0.67, 0.97, 0.36, 0.07, 0.63, 0.5 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "Read the following documentation and understand the code\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 120.19826684914514\n",
      "MSE of test dataset: 356.4868075878598\n",
      "Coefficients:\n",
      " [ 15.26455355  40.46800213 -10.21335792  27.4920002   -4.63610068\n",
      "  40.66508376   3.47899568  32.47264792  -9.79806108  34.04082205\n",
      "  -4.44214276  45.93739173  11.19814633  61.90038321  -1.29734991\n",
      "  65.33791401  14.1195483   72.16802276  -2.85811332  57.54438325]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lin_reg.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "coefs = lin_reg.coef_\n",
    "print('Coefficients:\\n', coefs) # contain 20 coefficients, not the independent coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516418022075496"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise. Linear regression with ridge regulation\n",
    "Read the documentation and edit the code above to get Linear regression with Ridge regulation. Try different alpha to see how it affects the model. Which alpha should we choose?\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 169.7320573163789\n",
      "MSE of test dataset: 300.460330778744\n",
      "Coefficients:\n",
      " [  5.37054384  37.84749771  -8.99011113  22.27589868  -3.58637528\n",
      "  26.6493153   -0.34966779  31.28105216 -11.73115988  26.40883294\n",
      "   0.4454349   39.88660581  13.56874581  49.87785979   3.9557953\n",
      "  57.06899624   8.49652793  58.47344108   0.24539891  45.10819341]\n",
      "Train score: 0.9317133548212774\n",
      " Test score: 0.8384773328175237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Your code here\n",
    "rid_reg = Ridge(alpha=0.7)\n",
    "rid_reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rid_reg.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_pred = rid_reg.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "coefs = rid_reg.coef_\n",
    "print('Coefficients:\\n', coefs) # contain 20 coefficients, not the independent coefficient\n",
    "\n",
    "score_train = rid_reg.score(X_train, y_train)\n",
    "score_test = rid_reg.score(X_test, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With alpha 1: \n",
    "Train score: 0.9175810801161374 \n",
    "Test score: 0.8319105110902633\n",
    "\n",
    "alpha 0.5:\n",
    "Train score: 0.9400103991439156\n",
    " Test score: 0.8389792067849651\n",
    " \n",
    "alpha 0.2:\n",
    "Train score: 0.9492855477526201\n",
    " Test score: 0.8288187223278736\n",
    " \n",
    "alpha 0.1:\n",
    "Train score: 0.9509966901433983\n",
    " Test score: 0.8205503942875743\n",
    " \n",
    " \n",
    "alpha 0.5 is the best (for test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise. Linear Regression with Lasso regulation\n",
    "The same question as Exercise 3, with lasso.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 123.94206644278037\n",
      "MSE of test dataset: 326.69112385728096\n",
      "Coefficients:\n",
      " [11.54630312 40.79030357 -8.58883024 25.50053725 -2.56809473 36.90869972\n",
      "  1.84081467 31.3209008  -7.55390147 31.32409054 -1.30193042 44.61384862\n",
      " 10.61735501 60.59198544  0.         64.32910847 11.33198413 69.43211171\n",
      " -1.19278812 55.20251859]\n",
      "Train score: 0.9501355957871896\n",
      " Test score: 0.8243760780882365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Your code here\n",
    "reg = Lasso(alpha=0.1)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "coefs = reg.coef_\n",
    "print('Coefficients:\\n', coefs) # contain 20 coefficients, not the independent coefficient\n",
    "\n",
    "score_train = reg.score(X_train, y_train)\n",
    "score_test = reg.score(X_test, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With alpha 1: \n",
    "Train score: 0.8867234144723495\n",
    " Test score: 0.7669682024697592\n",
    " \n",
    "alpha 0.5:\n",
    "Train score: 0.9285132172062385\n",
    " Test score: 0.8316585840643945\n",
    " \n",
    "alpha 0.2:\n",
    "Train score: 0.9462787521650388\n",
    " Test score: 0.8342725340181228\n",
    "\n",
    "alpha 0.1:\n",
    "Train score: 0.9501355957871896\n",
    " Test score: 0.8243760780882365\n",
    " \n",
    "alpha 0.2 is best choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures\n",
    "\n",
    "## Exercise\n",
    "Try to do Polynomial Regression with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 1.1070810834999262e-26\n",
      "MSE of test dataset: 335.4725862555032\n",
      "Coefficients:\n",
      " [  0.23878316   0.08497305   4.50752602   0.97766033   5.5358902\n",
      "  -2.54075115   4.94670491  -6.94789545  -1.03532451  -5.14679153\n",
      "  -0.96442691  -3.52805289   3.50669789  -3.12226864   8.5037629\n",
      "  -1.18954345  11.82104386   4.39927852   6.11946868   0.36077221\n",
      "   8.61168513   7.31955863   2.63664178   5.09795969  -3.28395981\n",
      "   3.08933381  -0.22270594  -3.3968908   -5.04588285  -1.856867\n",
      "  12.81304423   2.88057135   7.82614821  -3.70908313  -3.45405888\n",
      "  -1.97145273   1.4909435   -4.42013715   2.68105208  -2.80986297\n",
      "   5.0726264    6.18758546   0.93407666  -3.32739339   7.95976819\n",
      "   3.47295044   2.12715223   2.63725748   2.68736269  13.90284749\n",
      "   3.91721584   0.80325992  -2.90887685  -1.82288956   8.75673251\n",
      "   3.733771    -2.40481475   7.76580325   2.58309373   1.34473181\n",
      "   1.68230074  -5.06410154  -2.5887426    1.47173176   0.25873745\n",
      "   5.61101015  -1.78389676  -2.7685393   -4.77820358  -4.02434502\n",
      "  -2.10597252   5.57586319  -4.60968379  -6.89051148  -3.21746578\n",
      "  -2.94932562  -7.04667053   0.36795101   9.91299181  10.83548376\n",
      "  -3.78961575   4.47529826  -2.00444025   2.46529687  -5.21044254\n",
      "  -0.06462985   1.60929989   7.25576662   5.23722001  -6.69010732\n",
      "   5.47848669   2.05038944   7.25615164   1.53488096   1.6078263\n",
      "   3.6201651    3.17003978  -6.43845228   5.37698069  -0.45945322\n",
      " -11.05791417  -6.06498847  -6.82170922  -1.91567755   3.07885593\n",
      "  -9.64148076   7.88792413   4.68116664   4.87877439  -5.43341577\n",
      "   2.63027262   9.71188765   6.57371375   2.75240694  -6.89193184\n",
      "   1.59627388   1.10340235   6.23191829  -3.77249335   9.16023502\n",
      "   4.69164716  -0.77468084  -0.6074572    5.3407111    2.70434824\n",
      "   2.13339463  -6.88391635  -0.32899507  -2.60603952 -12.84398721\n",
      "  -1.27752611  -3.12492629  -4.24658061   4.99054866   3.62901767\n",
      "  14.77654531   6.89387912   6.57862181  -0.37728581   0.46679587\n",
      "  11.78847509  -5.39221934  10.10640665   2.15296377   0.22714872\n",
      "  -2.96465435   7.53035251   1.38863804   0.83496451  -2.67370006\n",
      "  10.03096284   1.81501327  10.32332999   4.2386365   -0.2607017\n",
      "   1.38196881  -5.73696924   3.65080574  -4.09276528  -0.81911174\n",
      "  -0.74247235   6.08277997   9.01506064   1.49778542  -2.49130863\n",
      "   8.40233987   8.87429815   2.28826208   7.03771596   5.21193686\n",
      "   1.63932555   5.34995929   5.02165884   1.05755567   7.22967681\n",
      "   3.49794002   3.78660826   3.50459387  -0.66990281   2.31795034\n",
      "   1.46131073   1.74513924  -1.2762845    1.60916186  -5.17296329\n",
      "  -0.38570292  18.99974094  12.88297713   7.0164703    5.20147329\n",
      "   6.83306044   2.47041894   6.78278288   0.78929936   5.20282206\n",
      "   1.73954081   6.47539117  -1.2941011    3.75728115   0.50174109\n",
      "   7.74950574  -7.05744133   1.65432042  15.17449006   5.68967684\n",
      "  -2.71067631   0.40334567   1.29830185   7.71489396  18.49492667\n",
      "   4.70202707   0.44947675  -5.19049011   4.19019692  -1.33945486\n",
      "  12.94841813  17.58204013   4.48355486   2.15674184  -0.64816289\n",
      "   6.511722    11.7277778    0.23071399  -7.7391754   -6.9509113\n",
      "  17.61391262  -7.00034702   4.47708725  -1.65419748   6.93948528\n",
      "  16.69114636]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Your code here\n",
    "pol_pre = PolynomialFeatures(degree=2)\n",
    "X_train_poly = pol_pre.fit_transform(X_train)\n",
    "X_test_poly = pol_pre.fit_transform(X_test)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "y_train_pred = lin_reg.predict(X_train_poly)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test_poly)\n",
    "mse_test = np.mean((y_test-y_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "coefs = lin_reg.coef_\n",
    "print('Coefficients:\\n', coefs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      " Test score: 0.8196553043852749\n"
     ]
    }
   ],
   "source": [
    "score_train = lin_reg.score(X_train_poly, y_train)\n",
    "score_test = lin_reg.score(X_test_poly, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Try the following models in sklearn:\n",
    "- Support Vector Regressor\n",
    "- Decision Tree Regressor\n",
    "- Multi-layer Perceptron Regressor (Basic Neural Network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving datas\n",
    "temps = [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 2373.8196544876273\n",
      "MSE of test dataset: 1823.0074114975782\n",
      "Train score: 0.04496426292576361\n",
      " Test score: 0.019980379322200315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Instanciate regressor\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "# coefs = clf.coef_\n",
    "# print('Coefficients:\\n', coefs) \n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 0.0\n",
      "MSE of test dataset: 2869.6717844779105\n",
      "Train score: 1.0\n",
      " Test score: -0.542689643474092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instanciate regressor\n",
    "reg = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_test_pred = reg.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_test_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "# coefs = clf.coef_\n",
    "# print('Coefficients:\\n', coefs) \n",
    "\n",
    "score_train = reg.score(X_train, y_train)\n",
    "score_test = reg.score(X_test, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of train dataset: 8920.657780278954\n",
      "MSE of test dataset: 6887.331492721275\n",
      "Train score: -2.588961344333725\n",
      " Test score: -2.702519229712926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Instanciate regressor\n",
    "reg = MLPRegressor(alpha=1)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "mse_train = np.mean((y_train-y_train_pred)**2 )\n",
    "print('MSE of train dataset:', mse_train)\n",
    "\n",
    "y_test_pred = reg.predict(X_test)\n",
    "mse_test = np.mean((y_test-y_test_pred)**2 )\n",
    "print('MSE of test dataset:', mse_test)\n",
    "\n",
    "# coefs = clf.coef_\n",
    "# print('Coefficients:\\n', coefs) \n",
    "\n",
    "score_train = reg.score(X_train, y_train)\n",
    "score_test = reg.score(X_test, y_test)\n",
    "\n",
    "print(f'Train score: {score_train}\\n', f'Test score: {score_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
